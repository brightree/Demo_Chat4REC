# ë³€ê²½ ì‚¬í•­
    # multi_agent_chatbot
# ê°œì„ ì´ í•„ìš”í•œ ì‚¬í•­
    # ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ >> í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‚¬ìš©

from langchain.prompts import PromptTemplate
import streamlit as st
from dotenv import load_dotenv
import os
import json
import uuid
from datetime import datetime
from typing import Literal, TypedDict
import openai
from langgraph.graph import StateGraph
from supabase import create_client
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, OpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyMuPDFLoader
from langchain.chains import RetrievalQA
from langchain.docstore.document import Document

#from langchain_community.llms import OpenAI
#from langchain_community.embeddings import OpenAIEmbeddings

# ==========================
# ğŸ”§ í™˜ê²½ ì„¤ì • ë° ì´ˆê¸°í™”
# ==========================
load_dotenv()
api_key = os.getenv("MY_API_KEY")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

if not api_key:
    st.error("â—OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

client = openai.OpenAI(api_key=api_key)
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# ===============================
# ğŸ§± ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ===============================
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "conversation_id" not in st.session_state:
    st.session_state.conversation_id = f"conv_{uuid.uuid4().hex[:8]}"
if "turn_index" not in st.session_state:
    st.session_state.turn_index = 0

# ===========================
# ğŸ“ PDF ë¬¸ì„œ ì„ë² ë”© (Agent1)
# ===========================
@st.cache_resource
def load_or_create_rag_retriever(
    file_path: str,
    index_dir: str = "faiss_index",
    chunk_size: int = 700,
    chunk_overlap: int = 150,
) -> FAISS:
    if os.path.exists(index_dir):
        return FAISS.load_local(
            index_dir,
            OpenAIEmbeddings(api_key=api_key),
            allow_dangerous_deserialization=True  # âœ… ì—¬ê¸°ê°€ í•µì‹¬ì…ë‹ˆë‹¤
        ).as_retriever()


    # 1. PDF ì½ê¸° ë° ì²­í‚¹
    loader = PyMuPDFLoader(file_path)
    documents = loader.load()
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap
    )
    chunks = splitter.split_documents(documents)

    # 2. ì„ë² ë”© ë° FAISS ì €ì¥
    embeddings = OpenAIEmbeddings(api_key=api_key)
    db = FAISS.from_documents(chunks, embeddings)
    db.save_local(index_dir)
    return db.as_retriever()

rag_retriever = load_or_create_rag_retriever("Rag_Galaxy25_Ultra.pdf")
rag_chain = RetrievalQA.from_chain_type(llm=OpenAI(temperature=0), retriever=rag_retriever)

# ===========================
# ğŸ“š ê°•ì˜ ë°ì´í„° ì „ì²˜ë¦¬ (Agent2)
# ===========================

# ê°•ì˜ ë°ì´í„° ì½ê¸°
@st.cache_data
def load_course_data():
    try:
        with open("sales_learning_dummy_data.json", "r", encoding="utf-8") as f:
            return json.load(f)["courses"]
    except Exception as e:
        st.error(f"â—ê°•ì˜ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
        return []

course_data = load_course_data()

# ê°•ì˜ ë°ì´í„° ë­ì²´ì¸ ë¬¸ì„œë¡œ ë³€í™˜
def course_data_to_documents(course_data: list) -> list[Document]:
    docs = []
    for course in course_data:
        text = "\n".join([f"{key}: {value}" for key, value in course.items()])
        docs.append(Document(page_content=text, metadata={"title": course.get("title", "")}))
    return docs

# ì„ë² ë”© ë° ì²­í‚¹
@st.cache_resource
def create_course_rag_retriever(course_data: list, index_dir: str = "course_faiss_index") -> FAISS:
    from langchain.text_splitter import RecursiveCharacterTextSplitter

    if os.path.exists(index_dir):
        return FAISS.load_local(
            index_dir,
            OpenAIEmbeddings(api_key=api_key),
            allow_dangerous_deserialization=True
        ).as_retriever()

    docs = course_data_to_documents(course_data)
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    split_docs = splitter.split_documents(docs)

    embeddings = OpenAIEmbeddings(api_key=api_key)
    db = FAISS.from_documents(split_docs, embeddings)
    db.save_local(index_dir)
    return db.as_retriever()


# ==============================
# ğŸ§  LangGraph ìƒíƒœ ì •ì˜
# ==============================
class GraphState(TypedDict):
    user_query: str
    final_response: str
    route: Literal["agent1", "agent2"]

# ==============================
# ğŸ” ì˜ë„ ë¶„ë¥˜ ì—”ì§„ ë…¸ë“œ
# ==============================
def route_intent(state: GraphState) -> GraphState:
    user_query = state["user_query"]

    routing_prompt = f"""
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ì—¬ ë¶„ë¥˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‘ë‹µì€ í•­ìƒ **í•µì‹¬ì ì´ê³  ê°„ê²°í•˜ê²Œ**, **ì¹œê·¼í•˜ë©´ì„œë„ ì „ë¬¸ì ì¸ ì–´íˆ¬**ë¡œ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.

ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì´ ì–´ë–¤ ìœ í˜•ì¸ì§€ ë¶„ë¥˜í•´ ì£¼ì„¸ìš”.
- ì œí’ˆ ìŠ¤í™, ê¸°ëŠ¥, ë°°í„°ë¦¬, ì¹´ë©”ë¼ ë“± 'ì œí’ˆ ì •ë³´'ì— ëŒ€í•œ ì§ˆë¬¸ì´ë©´: agent1
- ì˜ì—… ê³ ë¯¼, ê°•ì˜ ì¶”ì²œ, í•™ìŠµì— ëŒ€í•œ ì§ˆë¬¸ì´ë©´: agent2
- ë‹¤ë§Œ, ì œí’ˆ ì •ë³´ì— ëŒ€í•œ ì§ˆë¬¸ì´ë”ë¼ë„ ë‹¨ìˆœ ì •ë³´ê°€ í•„ìš”í•œ ê²ƒì´ ì•„ë‹Œ ê°•ì˜ ì¶”ì²œì„ ìš”êµ¬í•˜ëŠ” ê²ƒì´ë¼ë©´ agent2ë¡œ ë¶„ë¥˜

â—ï¸ë°˜ë“œì‹œ ì•„ë˜ ì¤‘ í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš” (ë”°ì˜´í‘œ ì—†ì´ ë‹¨ë…ìœ¼ë¡œ í•œ ì¤„):
agent1
agent2

[ì‚¬ìš©ì ì§ˆë¬¸]
{user_query}
"""

    response = client.chat.completions.create(
        model="gpt-4.1-nano",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ë¥˜í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤."},
            {"role": "user", "content": routing_prompt}
        ]
    )

    raw = response.choices[0].message.content.strip().lower()

    # ì•ˆì •ì  ì²˜ë¦¬
    if "agent1" in raw:
        route = "agent1"
    elif "agent2" in raw:
        route = "agent2"
    else:
        # fallback: í•™ìŠµ ê´€ë ¨ìœ¼ë¡œ ì²˜ë¦¬
        route = "agent2"

    return {**state, "route": route}

# ==============================
# ğŸ¤– Agent1 (RAG ê¸°ë°˜ ì œí’ˆ ë‹µë³€)
# ==============================
agent1_prompt_template = PromptTemplate(
    input_variables=["user_query"],
    template="""
ë‹¹ì‹ ì€ ì‚¼ì„±ì „ì ì œí’ˆì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³  êµ¬ì¡°ì ì¸ í˜•íƒœë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.  
ê°€ëŠ¥í•˜ë‹¤ë©´ ë‹¤ìŒ í•­ëª©ì„ í¬í•¨í•˜ì—¬ ì •ë¦¬í•´ ì£¼ì„¸ìš”:

- **í•µì‹¬ ìš”ì•½**: ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ ì •ë³´ í•œë‘ ì¤„ ìš”ì•½  
- **ê¸°ëŠ¥ ì„¤ëª…**: ê´€ë ¨ëœ ì£¼ìš” ê¸°ëŠ¥ì´ë‚˜ íŠ¹ì§•  
- **ìŠ¤í™/ì„±ëŠ¥**: ê¸°ìˆ ì ì¸ ì‚¬ì–‘ ì •ë³´ (ìˆë‹¤ë©´)  
- **ë¹„êµ/ì°¨ì´ì **: ê´€ë ¨ ì œí’ˆê³¼ ë¹„êµê°€ í•„ìš”í•œ ê²½ìš° ê°„ë‹¨íˆ  
- **ì¶”ê°€ íŒ ë˜ëŠ” ì£¼ì˜ì‚¬í•­**: ì‚¬ìš©ì— ìœ ìš©í•œ ì •ë³´

ë‹¨ë‹µí˜•ì´ ì•„ë‹Œ, **ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ í†¤**ìœ¼ë¡œ ì‘ì„±í•˜ë©°  
ë¶ˆí•„ìš”í•œ ë°˜ë³µì´ë‚˜ ì¥í™©í•œ ì„¤ëª…ì€ í”¼í•˜ê³  ê°„ê²°í•˜ê²Œ ì „ë‹¬í•´ ì£¼ì„¸ìš”.
{user_query}
"""
)

def agent1_product_info(state: GraphState) -> GraphState:
    try:
        formatted_query = agent1_prompt_template.format(
            user_query=state["user_query"]
        )
        answer = rag_chain.run(formatted_query)
    except Exception as e:
        answer = f"â—ì œí’ˆ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
    return {**state, "final_response": answer}


# ==============================
# ğŸ“ Agent2 (ê°•ì˜ ì¶”ì²œ ì±—ë´‡)
# ==============================
# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
course_prompt_template = PromptTemplate(
    input_variables=["full_history", "course_data"],
    template="""
ë‹¹ì‹ ì€ ì‚¼ì„±ì „ì ì˜ì—…ì‚¬ì›ì„ ìœ„í•œ "ì „ë¬¸ ê°•ì˜ ì¶”ì²œ ì±—ë´‡"ì…ë‹ˆë‹¤.

## ì—­í• 
- ì‚¼ì„±ì „ì ì˜ì—…ì‚¬ì›ì´ ì œí’ˆ ì„¤ëª…, ê³ ê° ìƒë‹´, ì„¸ì¼ì¦ˆ ì „ëµ ë“± ì—…ë¬´ì—ì„œ ê²ªëŠ” ê³ ë¯¼ì„ ê¸°ë°˜ìœ¼ë¡œ, ê°€ì¥ ì í•©í•œ ê°•ì˜ë¥¼ ì¶”ì²œí•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.
- ì‚¬ìš©ìëŠ” ë°”ìœ ì—…ë¬´ ì¤‘ ì§ˆë¬¸í•˜ë¯€ë¡œ, ì‘ë‹µì€ í•­ìƒ **í•µì‹¬ì ì´ê³  ê°„ê²°í•˜ê²Œ**, **ì¹œê·¼í•˜ë©´ì„œë„ ì „ë¬¸ì ì¸ ì–´íˆ¬**ë¡œ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.

## ëª©í‘œ
- ì‚¬ìš©ìì˜ ê³ ë¯¼/ìƒí™©/ì„ í˜¸ ìŠ¤íƒ€ì¼ì„ íŒŒì•…í•˜ì—¬ ë§ì¶¤ ê°•ì˜ 3~5ê°œë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.
- ë‹¨, ì‚¬ìš©ìê°€ "ì§€ê¸ˆ ë°”ë¡œ ì¶”ì²œí•´ì¤˜"ë¼ê³  ë§í•˜ì§€ ì•ŠëŠ” ì´ìƒ, 2íšŒ ë‚´ì™¸ì˜ ìƒí˜¸ëŒ€í™”ë¥¼ í†µí•´ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    - ì˜ˆë¥¼ ë“¤ì–´, ë‹¨ìˆœí•œ ì¸ì‚¿ë§ë§Œ ì£¼ê³  ë°›ì•˜ë‹¤ë©´ ì›í•˜ëŠ” ê°•ì˜ë‚˜ í•™ìŠµ ê³ ë¯¼ì„ ìœ ë„ ì§ˆë¬¸í•˜ì—¬ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

## ëŒ€í™” íë¦„ ì§€ì¹¨ (Flow Logic)
1. **ì •ë³´ ìˆ˜ì§‘**
   - ì‚¬ìš©ìì˜ ì‘ë‹µì— ë”°ë¼ ìì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸ì„ ì´ì–´ê°€ë©°, í•œ ë²ˆì— í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ ë˜ì§‘ë‹ˆë‹¤.
   - ì§ˆë¬¸ì€ ì§§ê³  ëª…í™•í•˜ë˜, ì ì ˆí•œ ê°•ì˜ë¥¼ ì¶”ì²œí•  ìˆ˜ ìˆë„ë¡ ì§ˆë¬¸í•©ë‹ˆë‹¤.

2. **ì¦‰ì‹œ ì¶”ì²œ ì˜ˆì™¸**
   - ì‚¬ìš©ìê°€ ì¦‰ê°ì ì¸ ì¶”ì²œì„ ì›í•˜ë©´, 1íšŒ ì§ˆì˜ì‘ë‹µ ì´í›„ ë°”ë¡œ ì¶”ì²œì„ ì§„í–‰í•©ë‹ˆë‹¤.

3. **ì¶”ì²œ ì‘ë‹µ í˜•ì‹**
   - ê°•ì˜ëŠ” ë‹¤ìŒ ì •ë³´ë¥¼ ë‹´ë˜, ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•œ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤:
     - ê°•ì˜ ì œëª©
     - ì¶”ì²œ ì´ìœ  (ì‚¬ìš©ì ê³ ë¯¼ê³¼ ì—°ê²°)
     - ë§í¬: https://www.ubion.co.kr/ubion/
   - ì¶”ì²œ ê°•ì˜ëŠ” **ì¤‘ìš”ë„ ìˆœì„œë¡œ 3~5ê°œ**, í•­ëª©ë³„ë¡œ êµ¬ë¶„í•´ ì œì‹œí•©ë‹ˆë‹¤.

4. **ì˜ˆì™¸ ì‘ëŒ€**
   - ì‚¬ìš©ìê°€ ë†ë‹´, ê³¼ê²©í•œ í‘œí˜„, ìš•ì„¤ ë“±ì„ ì…ë ¥í•˜ë”ë¼ë„ ê°ì •ì  ëŒ€ì‘ ì—†ì´ ì›ë˜ ì£¼ì œë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ë„í•©ë‹ˆë‹¤.

## ì‘ë‹µ ìŠ¤íƒ€ì¼ (Tone & Format)
- ë§íˆ¬: ì „ë¬¸ì„± ìˆê³  ì¹œì ˆí•œ ë§íˆ¬
- ë¬¸ì¥: ì§§ê³  í•µì‹¬ì ìœ¼ë¡œ, ì •ë³´ ë°€ë„ ë†’ê²Œ
- ë¶ˆí•„ìš”í•œ ì„œë‘/ê²°ë¡ /ê³¼ì‰ ì„¤ëª… ë°°ì œ
- ì‚¬ìš©ìì˜ í‘œí˜„ì„ ìš”ì•½í•˜ë©° ë‹¤ìŒ ì§ˆë¬¸ ë˜ëŠ” ì¶”ì²œìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°

## ì‘ë‹µ ì˜ˆì‹œ (ì°¸ê³ ìš© í”„ë¼ì´ë°)
ì‚¬ìš©ì: ê³ ê° ì‘ëŒ€ê°€ í˜ë“¤ì–´ìš”  
â†’ ì±—ë´‡: ê³ ê° ëŒ€ì‘ì´ ì–´ë ¤ìš°ì‹œêµ°ìš”. í˜¹ì‹œ ì–´ë–¤ ìœ í˜•ì˜ ê³ ê°ì´ íŠ¹íˆ ì–´ë ¤ìš°ì…¨ë‚˜ìš”? ì˜ˆë¥¼ ë“¤ë©´ ë¶ˆë§Œ ê³ ê°, ì„¤ëª…ì„ ëª» ì•Œì•„ë“£ëŠ” ê³ ê° ë“±ìš”.  

ì‚¬ìš©ì: ì§‘ì¤‘ì´ ì˜ ì•ˆë¼ìš”.
â†’ ì±—ë´‡: ì§§ê³  í•µì‹¬ì ì¸ ê°•ì˜ë¥¼ ì¶”ì²œí•´ ë“œë¦´ê²Œìš”.
â†’ [ê°•ì˜ ì¶”ì²œ ì‹œì‘]


[ëŒ€í™” ê¸°ë¡]
{full_history}

ì´ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì¶”ê°€ ì§ˆë¬¸ì´ í•„ìš”í•˜ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ê³ ,  
ì •ë³´ê°€ ì¶©ë¶„í•˜ë‹¤ê³  íŒë‹¨ë˜ë©´ ê°•ì˜ë¥¼ ì¶”ì²œí•´ ì£¼ì„¸ìš”.


[ê°•ì˜ ëª©ë¡]
{course_data}
"""
)

# ê°•ì˜ ì¶”ì²œ
@st.cache_resource
def create_course_rag_retriever(course_data: list, index_dir: str = "course_faiss_index") -> FAISS:
    from langchain.text_splitter import RecursiveCharacterTextSplitter

    if os.path.exists(index_dir):
        return FAISS.load_local(
            index_dir,
            OpenAIEmbeddings(api_key=api_key),
            allow_dangerous_deserialization=True
        ).as_retriever()

    docs = course_data_to_documents(course_data)
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    split_docs = splitter.split_documents(docs)

    embeddings = OpenAIEmbeddings(api_key=api_key)
    db = FAISS.from_documents(split_docs, embeddings)
    db.save_local(index_dir)
    return db.as_retriever()

# ==============================
# ğŸ” LangGraph êµ¬ì¶•
# ==============================
builder = StateGraph(GraphState)
builder.add_node("route_intent", route_intent)
builder.add_node("agent1", agent1_product_info)
builder.add_node("agent2", agent2_recommend_courses)

builder.set_entry_point("route_intent")
builder.add_conditional_edges("route_intent", lambda x: x["route"], {
    "agent1": "agent1",
    "agent2": "agent2"
})

graph = builder.compile()

# ==============================
# ğŸ’¾ Supabase ì €ì¥ í•¨ìˆ˜
# ==============================
def save_chat_to_db(user_input, llm_response):
    supabase.table("chat_history").insert({
        "user_id": "guest_user",
        "conversation_id": st.session_state.conversation_id,
        "turn_index": st.session_state.turn_index,
        "timestamp": datetime.utcnow().isoformat(),
        "user_input": user_input,
        "llm_response": llm_response
    }).execute()
    st.session_state.turn_index += 1

# ==============================
# ğŸ¨ Streamlit UI
# ==============================
st.set_page_config(
    page_title="ì‚¼ì„± ì„¸ì¼ì¦ˆ Agentic ì±—ë´‡",
    page_icon="ğŸ’¼",
    layout="centered",
    initial_sidebar_state="collapsed"
)

for turn in st.session_state.chat_history:
    st.chat_message("user").write(turn["user"])
    st.chat_message("assistant").write(turn["bot"])

samsung_blue = "#1428A0"
st.markdown(f"""
    <div style="text-align:center; margin-bottom:20px;">
        <img src="https://upload.wikimedia.org/wikipedia/commons/2/24/Samsung_Logo.svg" width="180" />
        <h2 style="color:{samsung_blue};">ì‚¼ì„±ì „ì Sales Agentic Assitant</h2>
        <p style="font-size:15px;">ì œí’ˆ ìŠ¤í™ ì •ë³´ë¶€í„° ê³ ê° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ê³ ë¯¼ê¹Œì§€, ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!</p>
    </div>
""", unsafe_allow_html=True)

user_input = st.chat_input("ì„¸ì¼ì¦ˆ ê´€ë ¨ ê¶ê¸ˆì ì„ ë§ì”€í•´ ì£¼ì„¸ìš”.")
if user_input:
    st.chat_message("user").write(user_input)
    result = graph.invoke({"user_query": user_input})
    response_text = result["final_response"]
    
    # âœ… í˜„ì¬ ì‘ë‹µí•œ agent ì•Œë ¤ì£¼ê¸°
    route_used = result.get("route", "")
    if route_used == "agent1":
        response_header = "ğŸ“± [ì œí’ˆ ì •ë³´ Agent]"
    elif route_used == "agent2":
        response_header = "ğŸ“ [í•™ìŠµ ì¶”ì²œ Agent]"
    else:
        response_header = "ğŸ¤– [Agent ì‘ë‹µ]"

    st.chat_message("assistant").write(f"{response_header}\n\n{response_text}")
    
    st.session_state.chat_history.append({"user": user_input, "bot": f"{response_header}\n\n{response_text}"})
    save_chat_to_db(user_input, response_text)
