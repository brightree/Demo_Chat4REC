from dotenv import load_dotenv
import os
import json
from datetime import datetime
from typing import TypedDict, List, Dict
import openai
from langgraph.graph import StateGraph

# 1. í™˜ê²½ ë³€ìˆ˜ ë° OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
load_dotenv()
api_key = os.getenv("MY_API_KEY")
client = openai.OpenAI(api_key=api_key)

# 2. ê°•ì˜ ë°ì´í„° ë¡œë“œ
with open("sales_learning_dummy_data.json", "r", encoding="utf-8") as f:
    course_data = json.load(f)["courses"]

# 3. ìƒíƒœ êµ¬ì¡° ì •ì˜
class GraphState(TypedDict):
    user_query: str
    structured_filter: dict
    filtered_courses: List[Dict]
    final_response: str

# 4. ì¿¼ë¦¬ íŒŒì‹± í•¨ìˆ˜ (ìì—°ì–´ â†’ ì¡°ê±´ JSON)
def parse_query(state: GraphState) -> GraphState:
    field_names = ["course_id", "title", "description", "created_at", "user_rating",
                   "category", "difficulty", "avg_watch_time", "num_reviews", "tags"]

    prompt = f"""
ë„ˆëŠ” ì„¸ì¼ì¦ˆ í•™ìŠµ ë¶„ì„ ì±—ë´‡ì´ì•¼.
ì‚¬ìš©ì ìš”ì²­ì—ì„œ ì¡°ê±´ì„ ì¶”ì¶œí•´ì„œ JSON í•„í„° í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì¤˜.

ê°€ëŠ¥í•œ í•„ë“œëŠ” ë‹¤ìŒê³¼ ê°™ì•„:
{field_names}

ì¶œë ¥ ì˜ˆì‹œ:
{{
  "filters": {{
    "created_at": {{"after": "YYYY-MM-DD"}},
    "user_rating": {{"gte": 4.0}},
    "category": "ì‹¤ì „ ì„¸ì¼ì¦ˆ"
  }},
  "user_context": "ì„±ê³¼ ì••ë°•"
}}

ì‚¬ìš©ì ìš”ì²­:
'{state['user_query']}'
"""
    res = client.chat.completions.create(
        model="gpt-4.1-nano",
        messages=[
            {"role": "system", "content": "ìì—°ì–´ ìš”ì²­ì—ì„œ ì¡°ê±´ì„ ì¶”ì¶œí•˜ëŠ” JSON íŒŒì„œ"},
            {"role": "user", "content": prompt}
        ]
    )
    try:
        parsed = json.loads(res.choices[0].message.content)
    except:
        parsed = {}

    return {**state, "structured_filter": parsed}

# 5. ì¡°ê±´ì— ë”°ë¼ ê°•ì˜ í•„í„°ë§
def safe_parse_date(val):
    try:
        if isinstance(val, str):
            return datetime.fromisoformat(val)
    except Exception:
        return None
    return None

def evaluate_condition(key: str, value, condition) -> bool:
    # ë‹¨ìˆœ ê°’ ë¹„êµ
    if not isinstance(condition, dict):
        return value == condition

    # ë³µí•© ì¡°ê±´ (gte, lte, after, before ë“±)
    for op, comp in condition.items():
        if value is None or comp is None:
            return False
        
        if op == "gte":
            return value >= comp
        elif op == "lte":
            return value <= comp
        elif op == "after":
            val_dt = safe_parse_date(value)
            comp_dt = safe_parse_date(comp)
            return val_dt is not None and comp_dt is not None and val_dt > comp_dt
        elif op == "before":
            val_dt = safe_parse_date(value)
            comp_dt = safe_parse_date(comp)
            return val_dt is not None and comp_dt is not None and val_dt < comp_dt

    return False  # ì•Œ ìˆ˜ ì—†ëŠ” ì—°ì‚°ìì¼ ê²½ìš°

def filter_courses(state: GraphState) -> GraphState:
    filters = state["structured_filter"].get("filters", {})
    results = []

    for course in course_data:
        include = True

        for key, condition in filters.items():
            course_value = course.get(key)

            # ë¦¬ìŠ¤íŠ¸ ì¡°ê±´
            if isinstance(condition, list):
                if course_value not in condition:
                    include = False
                    break

            # ë‹¨ì¼ê°’/ë”•ì…”ë„ˆë¦¬ ì¡°ê±´
            elif not evaluate_condition(key, course_value, condition):
                include = False
                break

        if include:
            results.append(course)

    return {**state, "filtered_courses": results}



# 6. ì¶”ì²œ ì‘ë‹µ ìƒì„±
def generate_response(state: GraphState) -> GraphState:
    top_courses = state["filtered_courses"][:5]
    user_context = state["structured_filter"].get("user_context", "")

    summary_prompt = f"""
ë„ˆëŠ” ì„¸ì¼ì¦ˆ ëŸ¬ë‹ ì¶”ì²œ ì±—ë´‡ì´ì•¼.
ì‚¬ìš©ì ê³ ë¯¼ ë˜ëŠ” ë§¥ë½: "{user_context}"

ì•„ë˜ ê°•ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•´ì„œ ê°ê° ì–´ë–¤ ì´ìœ ë¡œ ì¶”ì²œí•˜ëŠ”ì§€ ê°„ê²°íˆ ì„¤ëª…í•´ì¤˜.
í˜•ì‹:
- ê°•ì˜ ì œëª©: ...
  ì¶”ì²œ ì´ìœ : ...

ê°•ì˜ ëª©ë¡:
{json.dumps(top_courses, ensure_ascii=False, indent=2)}
"""
    res = client.chat.completions.create(
        model="gpt-4.1-nano",
        messages=[
            {"role": "system", "content": "ì¶”ì²œ ìš”ì•½ ìƒì„±ê¸° (ì´ìœ  í¬í•¨)"},
            {"role": "user", "content": summary_prompt}]
    )
    return {**state, "final_response": res.choices[0].message.content.strip()}

# 7. LangGraph êµ¬ì„±
builder = StateGraph(GraphState)
builder.add_node("parse_query", parse_query)
builder.add_node("filter_courses", filter_courses)
builder.add_node("generate_response", generate_response)

builder.set_entry_point("parse_query")
builder.add_edge("parse_query", "filter_courses")
builder.add_edge("filter_courses", "generate_response")

graph = builder.compile()

# 8. ì‹¤í–‰ í•¨ìˆ˜
def run_chatbot(user_input: str):
    result = graph.invoke({"user_query": user_input})
    print("\nğŸ“š ê°•ì˜ ì¶”ì²œ ê²°ê³¼:\n")
    print(result["final_response"])

# 9. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    q = "ìµœê·¼ ì—…ë¡œë“œëœ ì‹¤ì „ ì„¸ì¼ì¦ˆ ê°•ì˜ ì¤‘ í‰ê·  ì‹œì²­ ì‹œê°„ì´ ê¸´ í¸ì´ê³ , ë¦¬ë·° ìˆ˜ê°€ ë§ì€ ê°•ì˜ ì¶”ì²œí•´ì¤˜. ë‚´ ê³ ë¯¼ì€ ì„±ê³¼ ì••ë°• ë•Œë¬¸ì— ë¬´ë¦¬í•œ ì„¤ë“ì„ ìì£¼ í•œë‹¤ëŠ” ê±°ì•¼."
    run_chatbot(q)
